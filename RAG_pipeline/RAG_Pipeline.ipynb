{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnsIq51I7qyn"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import TextSplitter, CharacterTextSplitter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySZjkE471isw"
      },
      "source": [
        "##Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y-6sSA97q37"
      },
      "outputs": [],
      "source": [
        "class data_ingestion:\n",
        "  def __init__(self, path:str, split_tech, chunk_size, chunk_overlap):\n",
        "    self.path = path\n",
        "    self.split_tech = split_tech\n",
        "    self.chunk_size = chunk_size\n",
        "    self.chunk_overlap = chunk_overlap\n",
        "\n",
        "  def data_load(self):\n",
        "\n",
        "    if self.path.split('.')[1].lower() == 'pdf':\n",
        "      print('pdf')\n",
        "      pdf_loader = PyPDFLoader(self.path)\n",
        "      text = pdf_loader.load()\n",
        "\n",
        "    if self.path.split('.')[1].lower() == 'txt':\n",
        "      print('txt')\n",
        "      txt_loader = TextLoader(self.path)\n",
        "      text = txt_loader.load()\n",
        "\n",
        "    if self.path.split('.')[1].lower() == 'docx':\n",
        "      print('docs')\n",
        "      doc_loader = Docx2txtLoader(self.path)\n",
        "      text = doc_loader.load()\n",
        "\n",
        "    return text\n",
        "\n",
        "  def splitter(self, texts):\n",
        "\n",
        "    if self.split_tech.lower() == 'recursive':\n",
        "      print('rec')\n",
        "      text_splitter = RecursiveCharacterTextSplitter(chunk_size = self.chunk_size, chunk_overlap = self.chunk_overlap)\n",
        "      documents = text_splitter.split_documents(texts)\n",
        "\n",
        "\n",
        "    if self.split_tech.lower() == 'char':\n",
        "      print('char')\n",
        "      text_splitter = CharacterTextSplitter(chunk_size = self.chunk_size, chunk_overlap = self.chunk_overlap)\n",
        "      documents = text_splitter.split_documents(texts)\n",
        "\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kqYgP8N8tWp",
        "outputId": "a23a7d87-8d6b-432e-e69b-4c490cc96a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pdf\n",
            "rec\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/CTGAN.pdf\"\n",
        "split_tech = 'recursive'\n",
        "# split_tech = 'char'\n",
        "chunk_size = 1000\n",
        "chunk_overlap = 100\n",
        "\n",
        "obj = data_ingestion(path, split_tech , chunk_size, chunk_overlap)\n",
        "\n",
        "text = obj.data_load()\n",
        "doc = obj.splitter(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYRVqXcAu3Eq",
        "outputId": "63b8e580-150c-4d5b-a749-7c95e10a1e88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K03uH8tn1op0"
      },
      "source": [
        "##embedding and vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNfzlQsL8tlj"
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import HuggingFaceHubEmbeddings\n",
        "# from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma, FAISS\n",
        "\n",
        "\n",
        "class embading_db:\n",
        "  def __init__(self, embedding, vector_db, emb_model):\n",
        "    self.embedding = embedding\n",
        "    self.vector_db = vector_db\n",
        "    self.embd_model = emb_model\n",
        "\n",
        "  def create_embedding(self):\n",
        "    if self.embedding == 'hugging':\n",
        "      print('hugging')\n",
        "      embedding = HuggingFaceHubEmbeddings(model= self.embd_model)\n",
        "\n",
        "    if self.embedding == 'openai':\n",
        "      print('openai')\n",
        "      embedding = OpenAIEmbeddings()\n",
        "\n",
        "    return embedding\n",
        "\n",
        "  def create_vectordb(self, document, embedding):\n",
        "    if self.vector_db == 'chroma':\n",
        "      print('chroma')\n",
        "      db = Chroma.from_documents(document, embedding, persist_directory=\"/content/\")\n",
        "\n",
        "    if self.vector_db == 'faiss':\n",
        "      print('faiss')\n",
        "      db = FAISS.from_documents(document, embedding)\n",
        "      db.save_local(\"faiss_index\")\n",
        "      print('done')\n",
        "\n",
        "    return db\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l96zD8KUrPMF",
        "outputId": "df544c7f-8b6b-4093-ef52-6e35aae3a083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openai\n",
            "chroma\n"
          ]
        }
      ],
      "source": [
        "embedding = 'openai'\n",
        "vector_db = 'chroma'\n",
        "emb_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "emb_obj = embading_db(embedding, vector_db, emb_model)\n",
        "emb = emb_obj.create_embedding()\n",
        "db = emb_obj.create_vectordb(doc, emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0cg3H89rPKL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CITVg2jerPGl"
      },
      "outputs": [],
      "source": [
        "text = \"This is a test query.\"\n",
        "query_result = emb.embed_query(text)\n",
        "query_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI7h6hffrPA4",
        "outputId": "1ea7f5f4-fffa-43fd-a991-c910c026de55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To address these challenges, in this paper, we propose conditional tabular GAN ( CTGAN )1, a method\n",
            "which introduces several new techniques: augmenting the training procedure with mode-speciﬁc\n",
            "normalization , architectural changes, and addressing data imbalance by employing a conditional\n",
            "generator andtraining-by-sampling (described in section 4). When applied to the same datasets\n",
            "with the benchmarking suite, CTGAN performs signiﬁcantly better than both the Bayesian network\n",
            "baselines and the other GANs tested, as shown in Table 1.\n",
            "The contributions of this paper are as follows:\n",
            "(1) Conditional GANs for synthetic data generation . We propose CTGAN as a synthetic tabular\n",
            "data generator to address several issues mentioned above. CTGAN outperforms all methods to date\n",
            "and surpasses Bayesian networks on at least 87.5% of our datasets. To further challenge CTGAN , we\n",
            "adapt a variational autoencoder (V AE) [ 15] for mixed-type tabular data generation. We call this TVAE .\n"
          ]
        }
      ],
      "source": [
        "\n",
        "query = \"What is ctgan\"\n",
        "retireved_results=db.similarity_search(query)\n",
        "print(retireved_results[0].page_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDOnY_jh1ewo"
      },
      "source": [
        "##RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAFmLA93H_J-"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vx20fnw4TwF"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "            Answer the following question based only on the provided context.\n",
        "            Think step by step before providing a detailed answer.\n",
        "            I will tip you $1000 if the user finds the answer helpful.\n",
        "            <context>\n",
        "            {context}\n",
        "            </context>\n",
        "            Question: {input}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi_J9Hs4_NmV"
      },
      "outputs": [],
      "source": [
        "class RAG:\n",
        "\n",
        "  def __init__(self, db, prompt, model_name, chain_type, temprature):\n",
        "    self.retriever = db.as_retriever()\n",
        "    self.prompt = prompt\n",
        "    self.model_name = model_name\n",
        "    self.chain_type = chain_type\n",
        "    self.temprature = temprature\n",
        "\n",
        "  def create_model(self):\n",
        "    if self.model_name == 'openai':\n",
        "      print('openai')\n",
        "      model = ChatOpenAI(temperature = self.temprature)\n",
        "\n",
        "    if self.model_name == 'llama':\n",
        "      pass\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "  def doc_stuff_chain(self, model):\n",
        "    if self.chain_type == 'retriver':\n",
        "      print('doc_stuff_chain')\n",
        "      document_chain = create_stuff_documents_chain(model, self.prompt)\n",
        "      retrieval_chain = create_retrieval_chain(self.retriever, document_chain)\n",
        "\n",
        "    return retrieval_chain, self.retriever\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj9DidoM_NYZ",
        "outputId": "d4e9c1d3-26f6-4d7a-ef9e-8c12937b7494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openai\n",
            "doc_stuff_chain\n"
          ]
        }
      ],
      "source": [
        "rag_obj = RAG(db, prompt, model_name='openai', chain_type='retriver', temprature=0.6)\n",
        "model = rag_obj.create_model()\n",
        "chain, context = rag_obj.doc_stuff_chain(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzevD2vIhdWa"
      },
      "outputs": [],
      "source": [
        "# print(query)\n",
        "# context.invoke('provide me details report on 7 wonders')[0]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "rJyz0voh4Lml",
        "outputId": "a77c2fd4-b2ea-4619-9ca0-c567040f4e47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Based on the provided context, the information pertains to datasets, deep generative models, and evaluation mechanisms. There is no mention of 7 wonders in the context provided. Would you like me to provide information on the 7 wonders of the world instead?'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chain.invoke({\"input\":\"provide me details report on 7 wonders\"})\n",
        "response['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "Iv-2ycqB4QG2",
        "outputId": "ec28e92f-9c5b-4600-80df-47549ad47f43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Based on the provided context, there is no specific information or guidance for providing medical advice or prescribing medication. It is important to consult a healthcare professional or doctor for accurate diagnosis and treatment recommendations for a fever or any other health condition. Please seek medical help from a qualified healthcare provider for appropriate medical assistance.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chain.invoke({\"input\":\"you are my health assistent, provide me a medicine for fiver\"})\n",
        "response['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL7ZyXd06uLS"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrtJQFsOl9Wu"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB9uARPtl7fr",
        "outputId": "c979a1b6-35a3-4812-ce2a-df8387dbb5a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/542.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/542.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets ragas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-pDFTfUmDdG"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from ragas.metrics import faithfulness\n",
        "from ragas import evaluate\n",
        "\n",
        "data_samples = {\n",
        "    'question': ['When was the first super bowl?', 'Who won the most super bowls?'],\n",
        "    'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],\n",
        "    'contexts' : [['The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,'],\n",
        "    ['The Green Bay Packers...Green Bay, Wisconsin.','The Packers compete...Football Conference']],\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset,metrics=[faithfulness])\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDs25IDpmIlJ"
      },
      "outputs": [],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# generator with openai models\n",
        "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")\n",
        "\n",
        "# generate testset\n",
        "testset = generator.generate_with_langchain_docs(doc, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFT7pFJumnH6"
      },
      "outputs": [],
      "source": [
        "eval_dataset = testset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHEJto0um250"
      },
      "outputs": [],
      "source": [
        "eval_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG3NfO0am6Uv"
      },
      "outputs": [],
      "source": [
        "test_questions = eval_dataset[\"question\"].values.tolist()\n",
        "test_groundtruths = eval_dataset[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIrycaOGnIXP"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke({\"input\" : 'what is ctgan'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KsMHSjnnQXb"
      },
      "outputs": [],
      "source": [
        "response[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JWDTnNanZqz"
      },
      "outputs": [],
      "source": [
        "for context in response[\"context\"]:\n",
        "  print(context.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-TaJbT2nAXJ"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "j88MX9canqB1",
        "outputId": "5012b2da-707c-4154-fb73-85bfe41fc5c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"eval_dataset\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"What is categorical reparameterization and its relation to GANs in modeling tabular data?\",\n          \"What is the significance of preventing mode collapse in the PacGAN framework?\",\n          \"What is the title of the paper that presents a framework for exploring and evaluating methods for predicting drug-induced laboratory test trajectories?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"The significance of preventing mode collapse in the PacGAN framework is to ensure that the generator produces diverse samples and does not get stuck in generating the same output. By using 10 samples in each pac, mode collapse is prevented, which helps in maintaining the diversity of generated samples.\",\n          \"The title of the paper that presents a framework for exploring and evaluating methods for predicting drug-induced laboratory test trajectories is 'Sequential Generative Adversarial Nets with Policy Gradient'\",\n          \"nan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evolution_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"simple\",\n          \"reasoning\",\n          \"multi_context\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode_done\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "eval_dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-92a0ff5d-0a42-45dd-bd34-dec2c0295dd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of auto-encoding vari...</td>\n",
              "      <td>[Improved training of wasserstein gans. In Adv...</td>\n",
              "      <td>nan</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': '/content/CTGAN.pdf', 'page': 9}]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92a0ff5d-0a42-45dd-bd34-dec2c0295dd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92a0ff5d-0a42-45dd-bd34-dec2c0295dd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92a0ff5d-0a42-45dd-bd34-dec2c0295dd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What is the significance of auto-encoding vari...   \n",
              "\n",
              "                                            contexts ground_truth  \\\n",
              "0  [Improved training of wasserstein gans. In Adv...          nan   \n",
              "\n",
              "  evolution_type                                       metadata  episode_done  \n",
              "0         simple  [{'source': '/content/CTGAN.pdf', 'page': 9}]          True  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib9WwMSgoEIR"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUcyakgsoh1c"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Convert list to pandas DataFrame\n",
        "dff = pd.DataFrame(response_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "nMtizgCdpTGH",
        "outputId": "41fe2d5d-4a01-4bcc-cc0b-05dab6f32e08"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dff\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"What is categorical reparameterization and its relation to GANs in modeling tabular data?\",\n          \"What is the significance of preventing mode collapse in the PacGAN framework?\",\n          \"What is the title of the paper that presents a framework for exploring and evaluating methods for predicting drug-induced laboratory test trajectories?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Categorical reparameterization is a technique used in machine learning, specifically in the context of Generative Adversarial Networks (GANs), to handle categorical variables. In the provided context, the reference to \\\"Categorical reparameterization with gumbel-softmax\\\" [13] suggests that this technique involves reparameterizing categorical variables using the Gumbel-Softmax distribution.\\n\\nIn the modeling of tabular data using GANs, categorical reparameterization is important because tabular data often contains a mix of discrete and continuous columns. Discrete columns in tabular data may be imbalanced, making modeling challenging for traditional statistical and deep neural network models. By reparameterizing categorical variables using techniques like Gumbel-Softmax, GANs can better handle the unique challenges posed by tabular data, such as simultaneously modeling discrete and continuous columns, multi-modal non-Gaussian values within continuous columns, and the imbalance of categorical columns.\\n\\nTherefore, categorical reparameterization plays a crucial role in improving the performance of GANs in modeling tabular data by addressing these challenges and enhancing the generation of realistic synthetic data.\",\n          \"Preventing mode collapse in the PacGAN framework is significant because it helps in generating more diverse and realistic synthetic data. Mode collapse occurs when a generative adversarial network (GAN) fails to capture all the modes or variations present in the data distribution, leading to repetitive or limited outputs. By addressing mode collapse in the PacGAN framework, it ensures that the generated data covers a wider range of variations, making it more representative of the original dataset. This ultimately improves the quality and effectiveness of the synthetic data generated by the GAN model.\",\n          \"The title of the paper that presents a framework for exploring and evaluating methods for predicting drug-induced laboratory test trajectories is \\\"Using generative adversarial networks for electronic health records: A framework for exploring and evaluating methods for predicting drug-induced laboratory test trajectories.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"The significance of preventing mode collapse in the PacGAN framework is to ensure that the generator produces diverse samples and does not get stuck in generating the same output. By using 10 samples in each pac, mode collapse is prevented, which helps in maintaining the diversity of generated samples.\",\n          \"The title of the paper that presents a framework for exploring and evaluating methods for predicting drug-induced laboratory test trajectories is 'Sequential Generative Adversarial Nets with Policy Gradient'\",\n          \"nan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dff"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c8ee5320-2864-4633-a9aa-ce22dff01983\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the significance of auto-encoding vari...</td>\n",
              "      <td>Auto-encoding variational bayes (VAE) is a neu...</td>\n",
              "      <td>[get as good a result as Bayesian networks. Wi...</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the significance of preventing mode co...</td>\n",
              "      <td>Preventing mode collapse in the PacGAN framewo...</td>\n",
              "      <td>[[21] Akash Srivastava, Lazar Valkov, Chris Ru...</td>\n",
              "      <td>The significance of preventing mode collapse i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are some examples of real datasets used i...</td>\n",
              "      <td>Some examples of real datasets used in the ben...</td>\n",
              "      <td>[7 Dataset Details\\nThe statistical informatio...</td>\n",
              "      <td>The real datasets used in the benchmark includ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the properties that make the task of ...</td>\n",
              "      <td>The properties that make the task of learning ...</td>\n",
              "      <td>[Mode-speciﬁc Normalization Generater Network ...</td>\n",
              "      <td>We observe that none of the existing deep gene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are some of the deep learning methods use...</td>\n",
              "      <td>Some of the deep learning methods used in the ...</td>\n",
              "      <td>[V AEs directly use data to build the generato...</td>\n",
              "      <td>The benchmarking system for synthetic data gen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8ee5320-2864-4633-a9aa-ce22dff01983')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8ee5320-2864-4633-a9aa-ce22dff01983 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8ee5320-2864-4633-a9aa-ce22dff01983');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d900ba5-44a0-4771-823e-3eabdb624ffc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d900ba5-44a0-4771-823e-3eabdb624ffc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d900ba5-44a0-4771-823e-3eabdb624ffc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What is the significance of auto-encoding vari...   \n",
              "1  What is the significance of preventing mode co...   \n",
              "2  What are some examples of real datasets used i...   \n",
              "3  What are the properties that make the task of ...   \n",
              "4  What are some of the deep learning methods use...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Auto-encoding variational bayes (VAE) is a neu...   \n",
              "1  Preventing mode collapse in the PacGAN framewo...   \n",
              "2  Some examples of real datasets used in the ben...   \n",
              "3  The properties that make the task of learning ...   \n",
              "4  Some of the deep learning methods used in the ...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [get as good a result as Bayesian networks. Wi...   \n",
              "1  [[21] Akash Srivastava, Lazar Valkov, Chris Ru...   \n",
              "2  [7 Dataset Details\\nThe statistical informatio...   \n",
              "3  [Mode-speciﬁc Normalization Generater Network ...   \n",
              "4  [V AEs directly use data to build the generato...   \n",
              "\n",
              "                                        ground_truth  \n",
              "0                                                nan  \n",
              "1  The significance of preventing mode collapse i...  \n",
              "2  The real datasets used in the benchmark includ...  \n",
              "3  We observe that none of the existing deep gene...  \n",
              "4  The benchmarking system for synthetic data gen...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dff.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a64xGDE-p8QQ"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "from ragas import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0oBi9oiqUo7"
      },
      "outputs": [],
      "source": [
        "score = evaluate(response_dataset, metrics=[faithfulness, answer_relevancy, context_recall, context_precision])\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuqd0FJ7qeEV",
        "outputId": "18efe771-47f0-4f51-bf00-2927cb41ef11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9625, 'answer_relevancy': 0.9742, 'context_recall': 0.7957, 'context_precision': 0.7639}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGUqCTVFrfWc"
      },
      "outputs": [],
      "source": [
        "res = score.to_pandas()\n",
        "res.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6caltlJDryrv"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    answer_similarity,\n",
        "    # context_entities_recall,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "    context_relevancy,\n",
        "    faithfulness\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWgcbaWiumqf"
      },
      "outputs": [],
      "source": [
        "score = evaluate(response_dataset, metrics=[faithfulness, context_relevancy, answer_relevancy, answer_correctness, answer_similarity, context_precision, context_recall])\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puIlPdByvkTo",
        "outputId": "24d9fba6-e6dc-44de-d8bf-7b8d71372b9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.9857, 'context_relevancy': 0.0425, 'answer_relevancy': 0.9720, 'answer_correctness': 0.5660, 'answer_similarity': 0.8930, 'context_precision': 0.7639, 'context_recall': 0.8457}"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT1tlgTEFlHB"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    answer_similarity,\n",
        "    # context_entities_recall,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "    context_relevancy,\n",
        "    faithfulness\n",
        "  )\n",
        "\n",
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jziumai9wda8"
      },
      "outputs": [],
      "source": [
        "class Evaluation_RAG:\n",
        "  def __init__(self, test_size):\n",
        "    self.test_size = test_size\n",
        "\n",
        "  def single_evatuation(self, query):\n",
        "\n",
        "    response = chain.invoke({\"input\" : query})\n",
        "    contexts = [context.page_content for context in response[\"context\"]]\n",
        "\n",
        "    answers = [response['answer']]\n",
        "    question = [query]\n",
        "    context = [[contexts[0]]]\n",
        "\n",
        "    response_dataset = Dataset.from_dict({\n",
        "          \"question\" : question,\n",
        "          \"answer\" : answers,\n",
        "          \"contexts\" : context\n",
        "      })\n",
        "\n",
        "    score = evaluate(response_dataset, metrics=[faithfulness, context_relevancy, answer_relevancy])\n",
        "\n",
        "    return score, response['answer']\n",
        "\n",
        "\n",
        "\n",
        "  def document_evatuation(self, document):\n",
        "\n",
        "    # generator with openai models\n",
        "    generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "    critic_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    generator = TestsetGenerator.from_langchain(\n",
        "        generator_llm,\n",
        "        critic_llm,\n",
        "        embeddings\n",
        "    )\n",
        "\n",
        "    # generate testset\n",
        "    testset = generator.generate_with_langchain_docs(document, test_size=self.test_size, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
        "    eval_dataset = testset.to_pandas()\n",
        "    test_questions = eval_dataset[\"question\"].values.tolist()\n",
        "    test_groundtruths = eval_dataset[\"ground_truth\"].values.tolist()\n",
        "\n",
        "    answers = []\n",
        "    contexts = []\n",
        "\n",
        "    for question in test_questions:\n",
        "      response = chain.invoke({\"input\" : question})\n",
        "      answers.append(response[\"answer\"])\n",
        "      contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n",
        "    response_dataset = Dataset.from_dict({\n",
        "          \"question\" : test_questions,\n",
        "          \"answer\" : answers,\n",
        "          \"contexts\" : contexts,\n",
        "          \"ground_truth\" : test_groundtruths\n",
        "      })\n",
        "\n",
        "    score = evaluate(response_dataset, metrics=[faithfulness, context_relevancy, answer_relevancy, answer_correctness, answer_similarity, context_precision, context_recall])\n",
        "    return score.to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f277dfe510a649f0b11f80be8ba9bd77",
            "b336473264d7428780878138c31dcc8f",
            "e58df754630942069c8c16a07b68ca7c",
            "c9a29460fd0c4395be2135920cd83f00",
            "c088c283ba0346e8a2ad32b919bcc868",
            "d1e8fe7c9d454a3d9f84c2b8e1759f82",
            "ad1354657cf640ff9e67704eef5fb054",
            "41dad2b7e64e47d6b46dd6b34bfd85f0",
            "a3a72fd4ee224a4caa9d1692d0b6bd9a",
            "092935715e11430b993146961e99f42f",
            "aa8529d8495a4b45b02029104cd10d5c"
          ]
        },
        "id": "oEWq7fynxWny",
        "outputId": "453e402f-d977-4eb9-f929-0b8d7eb07870"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f277dfe510a649f0b11f80be8ba9bd77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ev_obj = Evaluation_RAG(5)\n",
        "# result = ev_obj.document_evatuation(doc)\n",
        "query = 'what is ctgan'\n",
        "score, answer = ev_obj.single_evatuation(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoiDdw1KMOpa",
        "outputId": "7e7cede4-d403-486e-fbe0-5047a76e8055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question \n",
            " what is ctgan \n",
            "Answer \n",
            " CTGAN stands for Conditional Tabular Generative Adversarial Network. It is a method proposed in a research paper for modeling the probability distribution of rows in tabular data and generating realistic synthetic data. CTGAN introduces several new techniques such as mode-specific normalization, architectural changes, and addressing data imbalance through a conditional generator and training-by-sampling. It outperforms Bayesian network baselines and other GANs tested in the study. \n",
            "Scores\n",
            "  {'faithfulness': 1.0000, 'context_relevancy': 0.1875, 'answer_relevancy': 0.8541}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Question \\n {query} \\nAnswer \\n {answer} \\nScores\\n  {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i01bzQIHmBa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSjq0gKSOg85"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YduQsQjRtK4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usma1W4eZRSG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "092935715e11430b993146961e99f42f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41dad2b7e64e47d6b46dd6b34bfd85f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a72fd4ee224a4caa9d1692d0b6bd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa8529d8495a4b45b02029104cd10d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1354657cf640ff9e67704eef5fb054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b336473264d7428780878138c31dcc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e8fe7c9d454a3d9f84c2b8e1759f82",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1354657cf640ff9e67704eef5fb054",
            "value": "Evaluating: 100%"
          }
        },
        "c088c283ba0346e8a2ad32b919bcc868": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a29460fd0c4395be2135920cd83f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_092935715e11430b993146961e99f42f",
            "placeholder": "​",
            "style": "IPY_MODEL_aa8529d8495a4b45b02029104cd10d5c",
            "value": " 3/3 [00:06&lt;00:00,  2.23s/it]"
          }
        },
        "d1e8fe7c9d454a3d9f84c2b8e1759f82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58df754630942069c8c16a07b68ca7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41dad2b7e64e47d6b46dd6b34bfd85f0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3a72fd4ee224a4caa9d1692d0b6bd9a",
            "value": 3
          }
        },
        "f277dfe510a649f0b11f80be8ba9bd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b336473264d7428780878138c31dcc8f",
              "IPY_MODEL_e58df754630942069c8c16a07b68ca7c",
              "IPY_MODEL_c9a29460fd0c4395be2135920cd83f00"
            ],
            "layout": "IPY_MODEL_c088c283ba0346e8a2ad32b919bcc868"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
